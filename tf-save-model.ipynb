{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "X = df[['pressure', 'temperature', 'humidity']].values\n",
    "y = df[['rain']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymodel(X,y):\n",
    "\n",
    "    tf.random.set_seed(seed=0)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Create Keras model\n",
    "    model = keras.Sequential(name=\"mymodel\", layers=[\n",
    "        keras.layers.InputLayer(input_shape=(3), name=\"input\"),\n",
    "        keras.layers.Dense(3, activation=\"relu\", name=\"dense\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n",
    "    ])\n",
    "\n",
    "    print(\"Model architecture\")\n",
    "    model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train model\n",
    "    print(\"Training model\")\n",
    "    model.fit(x=[X_train], y=[y_train], batch_size=100, epochs=10)\n",
    "\n",
    "    # Test model\n",
    "    print(\"Testing model\")\n",
    "    test_loss, test_acc = model.evaluate(x=[X_test], y=[y_test], verbose=2)\n",
    "\n",
    "    print(\"Test accuracy: \", test_acc)\n",
    "\n",
    "    # Predict\n",
    "    #predictions = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mymodel(X, y)\n",
    "\n",
    "# Make SavedModel\n",
    "keras_model_path = os.path.join(MODEL_DIR, 'keras_model')\n",
    "tf.saved_model.save(model, keras_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(imported.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = imported.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(tf.constant(X, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Servable ML Model with Tensorflow\n",
    "In this notebook we will create, save, load, and employ models with Tensorflow. We will work through how to structure code to create models that can be saved and used for inference in the cloud or at the edge with applications such as dashboards, games, anomaly detection, and much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.0.0\n",
      "Numpy version: 1.16.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "print(\"Tensorflow version:\", tf.version.VERSION)\n",
    "print(\"Numpy version:\", np.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'models' # We will save model to this directory\n",
    "DATA_PATH = os.path.join('data', 'data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2 includes a [SavedModel](https://www.tensorflow.org/guide/saved_model \"Tensorflow SavedModel docs\") format that can be utilised for transfer learning and/or inference in applications. In order for a model to be saveable, it has to be of the type `tf.Module`. Keras models satisfy this criterium and are thus relatively simple to save. Before jumping into a specific example of a Keras model, we will, however, address the components of a Tensorflow SavedModel with a general example using pure Tensorflow.\n",
    "\n",
    "# General Example in Pure Tensorflow\n",
    "A Tensorflow SavedModel can be created from a `tf.Module`, so let us create a very simple example model using this object structure. The saved model will include any `tf.Modules`s, any methods with the `@tf.function` decorator, and any `tf.Variable`, but will not include any Python code or functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearScaler(tf.Module):\n",
    "    '''\n",
    "    LinearScaler is a very simple linear function that takes in a variable, multiplies it\n",
    "     by a weight and adds a bias before returning the result.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(LinearScaler, self).__init__()\n",
    "        self.bias = tf.Variable(1.)\n",
    "        self.weight = tf.Variable(2.)\n",
    "\n",
    "    @tf.function#(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "    def __call__(self, x):\n",
    "        '''\n",
    "        Linearly rescale y = x * weight + bias\n",
    "        :param x: The variable to be linearly scaled\n",
    "        :type x: tf.float32\n",
    "        :output y: y = x * weight + bias\n",
    "        '''\n",
    "        return x * self.weight + self.bias\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([], tf.float32), tf.TensorSpec([], tf.float32)])\n",
    "    def calibrate(self, weight, bias):\n",
    "        '''\n",
    "        Set the parameters of the linear function.\n",
    "        :param weight: Weight of the linear function\n",
    "        :type weight: tf.float32\n",
    "        :param bias: Bias of the linear function\n",
    "        :type bias: tf.float32\n",
    "        '''\n",
    "        self.weight.assign(weight)\n",
    "        self.bias.assign(bias)\n",
    "\n",
    "model = LinearScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make sure that is works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model(4).numpy() == 9 #  2 * 4 + 1\n",
    "model.calibrate(weight=5, bias=2)\n",
    "assert model(4).numpy() == 22 # 5 * 4 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! Now we have a working model. Let us go right ahead and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AEQN\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models\\no_signatures\\assets\n"
     ]
    }
   ],
   "source": [
    "no_signatures_path = os.path.join(MODEL_DIR, 'no_signatures')\n",
    "#model = LinearScaler() # Get a fresh model\n",
    "#model(tf.constant(4.))\n",
    "tf.saved_model.save(model, no_signatures_path) # Save the function to a dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is our model saved. Let us have a look at what is in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets', 'saved_model.pb', 'variables']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(no_signatures_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The saved model consists of several elements.<br>\n",
    "- `saved_model.pb` contains the model architecture that is used to rebuild the function\n",
    "- The directory `variables` contain one or more data files holding the values of the parameters in the model at the time it was saved. For large models with billions of parameters, these data files can grow large. A `variables.index` file maps the stored parameters to their right spot in the function\n",
    "- The directory `assets` holds additional artefacts needed to recreate the function, but should be empty in our case\n",
    "\n",
    "Fortunately, it is fairly straightforward to load the model again, as the `tf.saved_model.load` method handles everything for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.saved_model.load(no_signatures_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we try to use our model in the same way as the original, we are presented with a ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(loaded_model(4))\n",
    "except ValueError as e:\n",
    "    print(\"We got a ValueError:\\n\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded model is not as forgiving as our original model. Specifically, it will accept only tensor inputs and will return tensor outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=202, shape=(), dtype=float32, numpy=22.0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\with_signature\\assets\n"
     ]
    }
   ],
   "source": [
    "with_signature_path = os.path.join(MODEL_DIR, 'with_signature')\n",
    "call = model.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32)) # Get a one-stop function\n",
    "tf.saved_model.save(model, with_signature_path, signatures=call) # Save the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so there is a lot to unpack here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(module_with_signature_path)\n",
    "print(list(imported.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = imported.signatures[\"serving_default\"]\n",
    "infer(tf.constant(4, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer.mutate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(tf.constant([4,5,6], dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_multiple_signatures_path = os.path.join(model_dir, 'multiple_signatures')\n",
    "call = module.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n",
    "signatures = {\"serving_default\": call,\n",
    "              \"array_input\": module.__call__.get_concrete_function(tf.TensorSpec([None], tf.float32))}\n",
    "\n",
    "tf.saved_model.save(module, module_multiple_signatures_path, signatures=signatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(module_multiple_signatures_path)\n",
    "print(list(imported.signatures.keys()))\n",
    "infer = imported.signatures[\"serving_default\"]\n",
    "print(infer(tf.constant([[3,3,4],[2,1,2]], dtype=float)))\n",
    "infer = imported.signatures[\"array_input\"]\n",
    "print(infer(tf.constant([[3,3,4],[2,1,2]], dtype=float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imported.mutate(tf.constant(4, dtype=float),tf.constant(4, dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
